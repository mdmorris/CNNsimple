{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras.utils\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data:\n",
    "Using jetImages_signal.npz and jetImages_bkg.npz to train the neural network and using jetImages_signal_test.npz and jetImages_bkg_test.npz for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #list_ds = tf.data.Dataset.list_files('data/jetImages*.npz')\n",
    "# list_ds = tf.data.Dataset.list_files('/mnt/data/ml/ShowJetsData.npz')\n",
    "\n",
    "# l_jetImages = []\n",
    "# l_labels = []\n",
    "# n = 5 #take number of files\n",
    "# n_images = 0 #number of images in one file\n",
    "# for f1 in list_ds.take(n):\n",
    "#     print(f1.numpy())\n",
    "#     with np.load(f1.numpy()) as data:\n",
    "\n",
    "#         jetImages  = np.array(data['jetImages'])\n",
    "#         n_images += len(jetImages)\n",
    "#         l_jetImages.append(jetImages)\n",
    "#         labels  = data['labels']\n",
    "#         l_labels.append(labels)\n",
    "#         print(labels.shape)\n",
    "#         print(jetImages.shape)\n",
    "\n",
    "\n",
    "# l_jetImages = np.array(l_jetImages).reshape(n_images,16,16,1)\n",
    "# l_labels = np.array(l_labels).reshape(n_images,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336227,)\n",
      "(62025, 16, 16, 1)\n",
      "(62025, 2)\n",
      "(62025, 1)\n",
      "(62025, 1)\n",
      "\n",
      "(12405, 16, 16, 1)\n",
      "(12405, 2)\n",
      "(12405,)\n",
      "(12405,)\n",
      "\n",
      "(24810, 16, 16, 1)\n",
      "(24810, 2)\n",
      "(24810,)\n",
      "(24810,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/mnt/data/ml/ShowJetsDataTest.npz')\n",
    "# !ls /mnt/data/ml/\n",
    "images = data['jetImages']\n",
    "labels = data['labels']\n",
    "tau21 = data['tau21']\n",
    "chMult = data['chMult']\n",
    "\n",
    "## data = stack all of them, then split them up after\n",
    "\n",
    "print(chMult.shape)\n",
    "\n",
    "grid = np.size(images, 1)\n",
    "#ensure same number of signal vs. background and even split of z events\n",
    "qcd_im = images[np.where(labels[:,0] == 1)]\n",
    "qcd_tau = tau21[np.where(labels[:,0] == 1)]\n",
    "qcd_mult = chMult[np.where(labels[:,0] == 1)]\n",
    "\n",
    "if len(qcd_im) % 3 != 0:\n",
    "    qcd_im = qcd_im[:len(qcd_im)-(len(qcd_im) % 3)]\n",
    "    qcd_tau = qcd_tau[:len(qcd_im)-(len(qcd_im) % 3)]\n",
    "    qcd_mult = qcd_mult[:len(qcd_im)-(len(qcd_im) % 3)]\n",
    "\n",
    "z1_im = images[np.where(labels[:,1] == 1)]\n",
    "z1_im = z1_im[:int(len(qcd_im)/3)]\n",
    "z1_tau = tau21[np.where(labels[:,1] == 1)]\n",
    "z1_tau = z1_tau[:int(len(qcd_im)/3)]\n",
    "z1_mult = chMult[np.where(labels[:,1] == 1)]\n",
    "z1_mult = z1_mult[:int(len(qcd_im)/3)]\n",
    "\n",
    "z2_im = images[np.where(labels[:,2] == 1)]\n",
    "z2_im = z2_im[:int(len(qcd_im)/3)]\n",
    "z2_tau = tau21[np.where(labels[:,2] == 1)]\n",
    "z2_tau = z2_tau[:int(len(qcd_im)/3)]\n",
    "z2_mult = chMult[np.where(labels[:,2] == 1)]\n",
    "z2_mult = z1_mult[:int(len(qcd_im)/3)]\n",
    "\n",
    "z3_im = images[np.where(labels[:,3] == 1)]\n",
    "z3_im = z3_im[:int(len(qcd_im)/3)]\n",
    "z3_tau = tau21[np.where(labels[:,3] == 1)]\n",
    "z3_tau = z3_tau[:int(len(qcd_im)/3)]\n",
    "z3_mult = chMult[np.where(labels[:,3] == 1)]\n",
    "z3_mult = z1_mult[:int(len(qcd_im)/3)]\n",
    "\n",
    "qcd_lab = np.zeros([len(qcd_im), 2])\n",
    "qcd_lab[:,0] = 1\n",
    "z_lab = np.zeros([len(qcd_im), 2])\n",
    "z_lab[:,1] = 1\n",
    "images = np.vstack((qcd_im, z1_im, z2_im, z3_im))\n",
    "taus = np.hstack((qcd_tau, z1_tau, z2_tau, z3_tau))\n",
    "mults = np.hstack((qcd_mult, z1_mult, z2_mult, z3_mult))\n",
    "labels = np.vstack((qcd_lab, z_lab))\n",
    "n_data = len(images)\n",
    "images = images.reshape(n_data, grid, grid, 1)\n",
    "#split data into testing/training/validation\n",
    "testimages = images[::4]\n",
    "testlabels = labels[::4]\n",
    "testtaus = taus[::4]\n",
    "testmults = mults[::4]\n",
    "mask_im = np.ones(images.shape,dtype=bool)\n",
    "mask_im[::4] = 0\n",
    "mask_im[1::8] = 0\n",
    "mask_lab = np.ones(labels.shape,dtype=bool)\n",
    "mask_lab[::4] = 0\n",
    "mask_lab[1::8] = 0\n",
    "mask_tau = np.ones(taus.shape,dtype=bool)\n",
    "mask_tau[::4] = 0\n",
    "mask_tau[1::8] = 0\n",
    "mask_mult = np.ones(mults.shape,dtype=bool)\n",
    "mask_mult[::4] = 0\n",
    "mask_mult[1::8] = 0\n",
    "valimages = images[1::8]\n",
    "vallabels = labels[1::8]\n",
    "valtaus = taus[1::8]\n",
    "valmults = mults[1::8]\n",
    "trainimages = images[mask_im].reshape((n_data-len(testimages)-len(valimages)), grid, grid, 1)\n",
    "trainlabels = labels[mask_lab].reshape((n_data-len(testimages)-len(valimages)), 2)\n",
    "traintaus = taus[mask_tau].reshape((n_data-len(testimages)-len(valimages)), 1)\n",
    "trainmults = mults[mask_mult].reshape((n_data-len(testimages)-len(valimages)), 1)\n",
    "\n",
    "print(trainimages.shape)\n",
    "print(trainlabels.shape)\n",
    "print(traintaus.shape)\n",
    "print(trainmults.shape)\n",
    "print()\n",
    "print(valimages.shape)\n",
    "print(vallabels.shape)\n",
    "print(valtaus.shape)\n",
    "print(valmults.shape)\n",
    "print()\n",
    "print(testimages.shape)\n",
    "print(testlabels.shape)\n",
    "print(testtaus.shape)\n",
    "print(testmults.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import list of files\n",
    "\n",
    "# filelist = tf.data.Dataset.list_files(str('data/jetImages*.npz'))\n",
    "# initialize new array and concatenate / append array to initialized array [DOES NOT WORK] trying zip\n",
    "\n",
    "\n",
    "# for f1 in filelist_sig.take(1):\n",
    "#     with np.load(f1.numpy()) as data:\n",
    "#         jetImages = data['jetImages']\n",
    "#         labels = data['labels']\n",
    "        \n",
    "# dataset = tf.data.Dataset.from_tensor_slices((l_jetImages, l_labels))\n",
    "# batched_dataset = dataset.batch(4)\n",
    "\n",
    "\n",
    "#for batch in batched_dataset.take(1):\n",
    "#    print([arr.numpy() for arr in batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = 16\n",
    "\n",
    "# trainimages = l_jetImages[10:]\n",
    "# trainlabels = l_labels[10:]\n",
    "\n",
    "# testimages = l_jetImages[:10]\n",
    "# testlables = l_labels[:10]\n",
    "\n",
    "# print(trainimages.shape)\n",
    "# print(trainlabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = 16\n",
    "# # training data : 10,000 signal samples and 10,000 bkg samples\n",
    "# #traindata_sig = np.load('data/jetImages_signal.npz')\n",
    "# #traindata_bkg = np.load('data/jetImages_bkg.npz')\n",
    "# trainimages = np.concatenate((traindata_sig['jetImages'], traindata_bkg['jetImages']),axis=0)\n",
    "# trainlabels = np.concatenate((traindata_sig['labels'],traindata_bkg['labels']),axis=0)\n",
    "# # testing data : 10,000 signal samples and 10,000 bkg samples\n",
    "# testdata_sig = np.load('data/jetImages_signal_test.npz')\n",
    "# testdata_bkg = np.load('data/jetImages_bkg_test.npz')\n",
    "# testimages = np.concatenate((testdata_sig['jetImages'], testdata_bkg['jetImages']),axis=0)\n",
    "# testlabels = np.concatenate((testdata_sig['labels'], testdata_bkg['labels']),axis=0)\n",
    "\n",
    "# n_test = len(testlabels)\n",
    "# n_train = len(trainlabels)\n",
    "# trainimages = trainimages.reshape(n_train, grid, grid, 1)\n",
    "# testimages = testimages.reshape(n_test, grid, grid, 1)\n",
    "# print(trainimages.shape)\n",
    "# print(trainlabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((l_jetImages, l_labels))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((testimages, testlabels))\n",
    "\n",
    "# batched_test_dataset = test_dataset.batch(4)\n",
    "\n",
    "#for batch in batched_dataset.take(4):\n",
    "#  print([arr.numpy() for arr in batch])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a plot of data to see what it looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing -> spit data into training and testing; take 80% for training and 20% for testing.\n",
    "\n",
    "If using CNN, uncomment \".reshape(n_data, grid, grid, 1)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot input signal and background\n",
    "sig_trainimages = np.zeros_like(trainimages[1])\n",
    "bkg_trainimages = np.zeros_like(trainimages[1])\n",
    "for i in range(len(trainimages)):\n",
    "    if trainlabels[i,0] == 1:\n",
    "        sig_trainimages += trainimages[i]\n",
    "    else:\n",
    "        bkg_trainimages += trainimages[i]\n",
    "#signal\n",
    "display_sig = sig_trainimages.reshape(grid,grid)\n",
    "plt.grid(False)\n",
    "plt.imshow(display_sig, interpolation='nearest', origin='low', cmap = 'jet', norm=LogNorm())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#background\n",
    "display_bkg = bkg_trainimages.reshape(grid,grid)\n",
    "plt.grid(False)\n",
    "plt.imshow(display_bkg, interpolation='nearest', origin='low', cmap = 'jet', norm=LogNorm())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model():\n",
    "#     model = keras.Sequential([\n",
    "#         Conv2D(32, (11, 11), activation='relu',\n",
    "#                input_shape=(grid, grid, 1)),\n",
    "#         Conv2D(32, (3, 3), activation='relu'),\n",
    "#         MaxPool2D((2, 2)),\n",
    "# #         Dropout(0.2),\n",
    "#         Conv2D(32, (3, 3), activation='relu'),\n",
    "#         Conv2D(32, (3, 3), activation='relu'),\n",
    "#         MaxPool2D((2, 2)),\n",
    "# #         Dropout(0.2),\n",
    "#         Flatten(),\n",
    "#         #custom input layer\n",
    "#         Dense(64, activation=tf.nn.relu),\n",
    "#         Dense(64, activation=tf.nn.relu),\n",
    "# #         Dropout(0.2),\n",
    "#         Dense(1, activation=tf.nn.sigmoid)])\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#                 optimizer='adam',\n",
    "#                 metrics=['mean_squared_error', 'binary_crossentropy', 'accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_model():\n",
    "    input1 = layers.Input(shape = (grid, grid, 1))\n",
    "    x = layers.Conv2D(64, (12, 12), activation='relu', padding = 'same')(input1)\n",
    "    x = layers.Conv2D(64, (6, 6), activation='relu', padding = 'same')(x)\n",
    "    x = layers.Conv2D(64, (4, 4), activation='relu', padding = 'same')(x)\n",
    "    x = layers.MaxPool2D((2, 2))(x)\n",
    "    x1 = layers.Flatten()(x)\n",
    "    input2 = layers.Input(shape=(1,))\n",
    "    #input3 = layers.Input(shape=(1,))\n",
    "    #input4 = layers.Input(shape=(1,))\n",
    "    x = layers.concatenate(inputs = [x1, input2],axis=-1)\n",
    "    x = layers.Dense(256, activation=tf.nn.relu)(x)\n",
    "    output = layers.Dense(2, activation=tf.nn.sigmoid)(x)\n",
    "    model = models.Model(inputs=[input1, input2], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['categorical_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "circleCNN = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model's prediction $before$ training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 1)\n",
      "(207, 16, 16, 1)\n",
      "(207, 1)\n",
      "207/207 [==============================] - 0s 2ms/step\n",
      "[[0.5025403  0.49960783]\n",
      " [0.5037716  0.49885908]\n",
      " [0.5045614  0.4982309 ]\n",
      " [0.5042055  0.49881977]\n",
      " [0.5056183  0.49802828]\n",
      " [0.50475615 0.49831176]\n",
      " [0.506357   0.49734217]\n",
      " [0.5058     0.49803948]\n",
      " [0.5038267  0.4987353 ]\n",
      " [0.5055017  0.4984029 ]\n",
      " [0.5034248  0.499143  ]\n",
      " [0.50505626 0.49818018]\n",
      " [0.50419474 0.4985114 ]\n",
      " [0.5030866  0.4991826 ]\n",
      " [0.5047773  0.4984386 ]\n",
      " [0.5063556  0.49796012]\n",
      " [0.5041134  0.49858603]\n",
      " [0.5043482  0.49859974]\n",
      " [0.5044526  0.4981297 ]\n",
      " [0.50524753 0.49819672]\n",
      " [0.507083   0.49741948]\n",
      " [0.5055952  0.49808055]\n",
      " [0.5063224  0.4974431 ]\n",
      " [0.50480604 0.49822834]\n",
      " [0.50579685 0.49761608]\n",
      " [0.50532883 0.4980293 ]\n",
      " [0.5042604  0.4986101 ]\n",
      " [0.5053842  0.49785152]\n",
      " [0.50579    0.4980713 ]\n",
      " [0.5065559  0.4980944 ]\n",
      " [0.5056213  0.49824575]\n",
      " [0.50601524 0.49774393]\n",
      " [0.50645643 0.49717927]\n",
      " [0.5056187  0.49777597]\n",
      " [0.5067769  0.4976396 ]\n",
      " [0.50537515 0.49773383]\n",
      " [0.5049838  0.49825102]\n",
      " [0.50472796 0.49819762]\n",
      " [0.5036496  0.49888352]\n",
      " [0.5029976  0.49952838]\n",
      " [0.50354517 0.49919087]\n",
      " [0.504385   0.49817637]\n",
      " [0.5062453  0.49808875]\n",
      " [0.5062887  0.4981021 ]\n",
      " [0.5062804  0.49742517]\n",
      " [0.50489974 0.49820396]\n",
      " [0.505205   0.49836946]\n",
      " [0.50534195 0.49771124]\n",
      " [0.50466466 0.49817482]\n",
      " [0.5041921  0.49881175]\n",
      " [0.50551283 0.49869835]\n",
      " [0.5029944  0.49962524]\n",
      " [0.5047784  0.4985847 ]\n",
      " [0.50531673 0.49836853]\n",
      " [0.50546485 0.4977812 ]\n",
      " [0.50545245 0.49788117]\n",
      " [0.5063051  0.49778125]\n",
      " [0.5054327  0.49886012]\n",
      " [0.50495017 0.4983384 ]\n",
      " [0.50637084 0.4976742 ]\n",
      " [0.5060542  0.49693745]\n",
      " [0.50494784 0.49837902]\n",
      " [0.5044309  0.49876195]\n",
      " [0.5060545  0.4981528 ]\n",
      " [0.5045212  0.4985004 ]\n",
      " [0.50608444 0.49749398]\n",
      " [0.505026   0.49876526]\n",
      " [0.50627255 0.49784383]\n",
      " [0.50577724 0.49796757]\n",
      " [0.50637054 0.49749157]\n",
      " [0.50578594 0.49790266]\n",
      " [0.5060759  0.4985933 ]\n",
      " [0.50324154 0.49943617]\n",
      " [0.5058518  0.49824306]\n",
      " [0.50323695 0.49897847]\n",
      " [0.5051379  0.4987058 ]\n",
      " [0.50583637 0.4979207 ]\n",
      " [0.504241   0.49883005]\n",
      " [0.50372773 0.49897248]\n",
      " [0.50475496 0.498975  ]\n",
      " [0.5052709  0.49814445]\n",
      " [0.50510204 0.49897516]\n",
      " [0.50504833 0.49809062]\n",
      " [0.50275177 0.49983743]\n",
      " [0.5048702  0.49809167]\n",
      " [0.50586677 0.4976026 ]\n",
      " [0.503275   0.5002263 ]\n",
      " [0.50622153 0.49791482]\n",
      " [0.5057897  0.4981492 ]\n",
      " [0.5057182  0.49765417]\n",
      " [0.50506777 0.49812886]\n",
      " [0.50366807 0.49907   ]\n",
      " [0.50595206 0.49806148]\n",
      " [0.5021196  0.49974373]\n",
      " [0.50571656 0.49786428]\n",
      " [0.5022993  0.49937758]\n",
      " [0.50438243 0.4988096 ]\n",
      " [0.5034017  0.4991314 ]\n",
      " [0.5048661  0.4983765 ]\n",
      " [0.50140345 0.4996424 ]\n",
      " [0.50279266 0.49940622]\n",
      " [0.5059488  0.4984589 ]\n",
      " [0.50556344 0.49816838]\n",
      " [0.5032983  0.49903855]\n",
      " [0.5064572  0.498041  ]\n",
      " [0.50318754 0.49923134]\n",
      " [0.5061585  0.49808758]\n",
      " [0.5023257  0.49986818]\n",
      " [0.50287545 0.4990547 ]\n",
      " [0.5014224  0.50012815]\n",
      " [0.50181425 0.5003537 ]\n",
      " [0.5014107  0.50011903]\n",
      " [0.50373    0.49989077]\n",
      " [0.5021581  0.4993965 ]\n",
      " [0.50187576 0.49980333]\n",
      " [0.5022365  0.49970675]\n",
      " [0.5049502  0.49848425]\n",
      " [0.50606215 0.49798524]\n",
      " [0.50613886 0.49787012]\n",
      " [0.50190353 0.50060636]\n",
      " [0.50596744 0.49762192]\n",
      " [0.50623536 0.49802005]\n",
      " [0.5026654  0.49955285]\n",
      " [0.50606346 0.49756962]\n",
      " [0.5029984  0.4996179 ]\n",
      " [0.50434744 0.49847415]\n",
      " [0.50661904 0.49802607]\n",
      " [0.5051381  0.49876022]\n",
      " [0.5055876  0.49837905]\n",
      " [0.5055365  0.4982073 ]\n",
      " [0.5021833  0.499559  ]\n",
      " [0.502198   0.49950674]\n",
      " [0.5038109  0.49919453]\n",
      " [0.503723   0.4988181 ]\n",
      " [0.504637   0.49900526]\n",
      " [0.5065144  0.4976114 ]\n",
      " [0.50352174 0.49888888]\n",
      " [0.5016076  0.50006866]\n",
      " [0.5024222  0.49979958]\n",
      " [0.5020982  0.5001367 ]\n",
      " [0.5022085  0.4997598 ]\n",
      " [0.5022346  0.49946302]\n",
      " [0.50415343 0.49853376]\n",
      " [0.50402534 0.4990458 ]\n",
      " [0.50363326 0.49934655]\n",
      " [0.5060169  0.4982301 ]\n",
      " [0.5057783  0.49762207]\n",
      " [0.50180763 0.49964765]\n",
      " [0.50382566 0.49911734]\n",
      " [0.50306416 0.49966893]\n",
      " [0.5012755  0.5002206 ]\n",
      " [0.5019035  0.4999903 ]\n",
      " [0.5023214  0.4991637 ]\n",
      " [0.502394   0.49979338]\n",
      " [0.50181174 0.4996004 ]\n",
      " [0.5066494  0.49746937]\n",
      " [0.50314015 0.49991724]\n",
      " [0.50149167 0.50043654]\n",
      " [0.50249374 0.49980754]\n",
      " [0.5016091  0.49993274]\n",
      " [0.5034629  0.49887824]\n",
      " [0.50307447 0.49951047]\n",
      " [0.504237   0.49851814]\n",
      " [0.502876   0.49855104]\n",
      " [0.50263226 0.49969137]\n",
      " [0.50231785 0.50002784]\n",
      " [0.50303745 0.4994366 ]\n",
      " [0.50167125 0.50044674]\n",
      " [0.5025833  0.4997245 ]\n",
      " [0.5032139  0.4996655 ]\n",
      " [0.5020337  0.5000046 ]\n",
      " [0.5026131  0.49953833]\n",
      " [0.5032736  0.49927366]\n",
      " [0.5049887  0.4988644 ]\n",
      " [0.50187254 0.5000152 ]\n",
      " [0.5043245  0.49846718]\n",
      " [0.50158453 0.5002907 ]\n",
      " [0.50439775 0.49923235]\n",
      " [0.5009518  0.5004148 ]\n",
      " [0.50343883 0.49912256]\n",
      " [0.5039895  0.49912   ]\n",
      " [0.5034586  0.49925977]\n",
      " [0.50272673 0.50020206]\n",
      " [0.5027178  0.49937385]\n",
      " [0.50335044 0.49937946]\n",
      " [0.50166726 0.49985364]\n",
      " [0.5032759  0.49987206]\n",
      " [0.5025875  0.4996658 ]\n",
      " [0.5021487  0.4994593 ]\n",
      " [0.5028458  0.49954382]\n",
      " [0.5030822  0.4989423 ]\n",
      " [0.5016754  0.49970055]\n",
      " [0.5032301  0.4993908 ]\n",
      " [0.50568366 0.49832967]\n",
      " [0.5020383  0.5002564 ]\n",
      " [0.505395   0.49804515]\n",
      " [0.5029282  0.49941432]\n",
      " [0.5020714  0.49992952]\n",
      " [0.5028058  0.4997649 ]\n",
      " [0.5014861  0.49990344]\n",
      " [0.502209   0.49978518]\n",
      " [0.50326616 0.49965826]\n",
      " [0.50477445 0.49795157]\n",
      " [0.504082   0.49858394]\n",
      " [0.5037429  0.499005  ]\n",
      " [0.5031231  0.49976417]\n",
      " [0.5040934  0.49870375]]\n",
      "[0.6918877579163814, 0.6918877579163814, 0.5024154589371981]\n"
     ]
    }
   ],
   "source": [
    "example_batch = trainimages[::300]\n",
    "example_labels = trainlabels[::300]\n",
    "example_taus = traintaus[::300]\n",
    "example_mults = trainmults[::300]\n",
    "print(example_taus.shape)\n",
    "print(example_batch.shape)\n",
    "print(example_mults.shape)\n",
    "\n",
    "\n",
    "example_result = circleCNN.predict(x = [example_batch, example_taus])\n",
    "results = circleCNN.evaluate(x = [example_batch, example_taus], y = example_labels)\n",
    "print(example_result)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_batch = trainimages[:10]\n",
    "# example_labels = trainlabels[:10]\n",
    "# example_result = circleCNN.predict(example_batch)\n",
    "# results = circleCNN.evaluate(example_batch, example_labels)\n",
    "# print(example_result)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train! (warning: if building CNN, computer tends to get loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67610, saving model to model/CNN_cat_multi_input.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67610 to 0.63296, saving model to model/CNN_cat_multi_input.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63296 to 0.58685, saving model to model/CNN_cat_multi_input.h5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.58685\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.58685\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.58685\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.58685\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58685\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58685\n"
     ]
    }
   ],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('')\n",
    "        print('.', end='')\n",
    "    \n",
    "checkpoint_path = \"model/CNN_cat_multi_input.h5\"\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "# Create checkpoint callback\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "#                                                  save_best_only=True,\n",
    "#                                                  verbose=1)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', \n",
    "                                   verbose=1, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto', \n",
    "                                   period=1)    \n",
    "EPOCHS = 50\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = circleCNN.fit(\n",
    "  #[trainimages, traintaus, trainmults], trainlabels,\n",
    "  [trainimages, traintaus], trainlabels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose = 0,\n",
    "  callbacks=[early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_shuffled = dataset.shuffle(buffer_size=1024).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WITH BATCHING AND SHUFFLING\n",
    "\n",
    "\n",
    "\n",
    "# EPOCHS = 1\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# history = circleCNN.fit(\n",
    "#   dataset_shuffled,\n",
    "#   epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a plot that shows the pregression of accuracy through each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history):\n",
    "#     hist = pd.DataFrame(history.history)\n",
    "#     hist['epoch'] = history.epoch\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Mean Square Error')\n",
    "#     plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "#              label='Train Error')\n",
    "#     plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "#              label = 'Val Error')\n",
    "#     plt.ylim([0,100])\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_cat_multi_input_3inputs.h5\tCNN_cat_multi_input.h5\t     CNN_sparce_cat.h5\n",
      "CNN_cat_multi_input_5E.h5\tCNN_cat_multi_input_taus.h5  RNN.h5\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16, 16, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 64)   9280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 64)   147520      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 64)   65600       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4097)         0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          1049088     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            514         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,272,002\n",
      "Trainable params: 1,272,002\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "24810/24810 [==============================] - 45s 2ms/step\n",
      "[0.4854704086312552, 0.4854704086312552, 0.7769850866634103]\n"
     ]
    }
   ],
   "source": [
    "!ls model\n",
    "best_model = keras.models.load_model('model/CNN_cat_multi_input_taus.h5')\n",
    "best_model.summary()\n",
    "#results = best_model.evaluate([testimages, testtaus, testmults], testlabels)\n",
    "results = best_model.evaluate([testimages, testtaus], testlabels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of our DNN! Plot predictions vs. true values (the line is predictions vs. predicitons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24810,)\n",
      "(24810, 16, 16, 1)\n",
      "(24810, 2)\n"
     ]
    }
   ],
   "source": [
    "# Plot ROC\n",
    "\n",
    "print(testtaus.shape)\n",
    "print(testimages.shape)\n",
    "print(testlabels.shape)\n",
    "\n",
    "#predict = best_model.predict([testimages, testtaus, testmults])\n",
    "predict = best_model.predict([testimages, testtaus])\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(testlabels[:,0], predict[:,0])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=2, color='b', label='auc = %.3f' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('receiver operating curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indqcd = np.argwhere(testlabels[:,1] == 0)\n",
    "ind1  = np.where(testlabels[:,1] == 1) \n",
    "# ind2  = np.where(testlabels[:,2] == 1)\n",
    "# ind3  = np.where(testlabels[:,3] == 1)\n",
    "hist_, bin_edges_ = np.histogram(predict[indqcd])\n",
    "plt.hist([predict[indqcd, 0].flatten(),predict[ind1, 1].flatten()] , histtype = 'step', label = ['qcd', 'ZZ'])\n",
    "plt.legend()\n",
    "plt.title('Predictions w/o normalized Pt')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Prediction (correct = 1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{LRP} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import innvestigate\n",
    "# import innvestigate.utils as iutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating an analyzer\n",
    "# lrp_analyzer = innvestigate.create_analyzer(\"lrp.z\", best_model)\n",
    "# #discoverered that innvestigate fails to run on a loaded model --> trying to find fix\n",
    "\n",
    "# # Applying the analyzer\n",
    "# display = trainimages[1].reshape(1,grid,grid,1) #the reshape is this way is because the input is expected to be 4 dimensions\n",
    "# analysis = lrp_analyzer.analyze(display)\n",
    "\n",
    "# # Displaying one result\n",
    "# plt.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fix - change to predicted labels\n",
    "# #plot output signal and background\n",
    "# sig_analysis_true = np.zeros_like(analysis)\n",
    "# bkg_analysis_true = np.zeros_like(analysis)\n",
    "# sig_analysis_pred = np.zeros_like(analysis)\n",
    "# bkg_analysis_pred = np.zeros_like(analysis)\n",
    "# # sig_mask = trainlabels == 1\n",
    "# # bkg_mask = trainlabels == 0\n",
    "# # pred_sig_mask = predict >= 0.50\n",
    "# # pred_bkg_mask = predict < 0.50\n",
    "\n",
    "# toc = time.time()\n",
    "\n",
    "# for i in range(len(trainimages)):\n",
    "#     display = trainimages[i].reshape(1,grid,grid,1)\n",
    "#     analysis = lrp_analyzer.analyze(display)\n",
    "#     if trainlabels[i] == 1:\n",
    "#         sig_analysis_true += analysis  \n",
    "#     else:\n",
    "#         bkg_analysis_true += analysis\n",
    "\n",
    "# for i in range(len(trainimages)):\n",
    "#     display = trainimages[i].reshape(1,grid,grid,1)\n",
    "#     analysis = lrp_analyzer.analyze(display)\n",
    "#     if trainlabels[i] >= 0.50:\n",
    "#         sig_analysis_pred += analysis  \n",
    "#     else:\n",
    "#         bkg_analysis_pred += analysis\n",
    "\n",
    "# tic = time.time()\n",
    "\n",
    "# print('/n time = /n', tic-toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the signal result\n",
    "# ax = plt.figure(figsize = (10,10))\n",
    "# ax.add_subplot(121)\n",
    "# im = plt.imshow(sig_analysis_true.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "# plt.colorbar(im,fraction=0.046, pad=0.04)\n",
    "# ax.add_subplot(122)\n",
    "# im_ = plt.imshow(sig_analysis_pred.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "# plt.colorbar(im_,fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Displaying the signal result\n",
    "# ax = plt.figure(figsize = (10,10))\n",
    "# plt.subplot(121)\n",
    "# im_ = plt.imshow(bkg_analysis_true.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "# plt.colorbar(im_,fraction=0.046, pad=0.04)\n",
    "# plt.subplot(122)\n",
    "# im = plt.imshow(bkg_analysis_pred.squeeze(), cmap='seismic', interpolation='nearest')\n",
    "# plt.colorbar(im,fraction=0.046, pad=0.04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
